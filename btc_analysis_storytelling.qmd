---
title: "BTC Hourly Close — A Data Story"
author: "Nadhir Benhalima"
format:
  html:
    toc: true
    toc-depth: 3
execute:
  echo: true
  warning: false
  message: false
---

# Introduction: Three Questions

This report tells a data story about BTC hourly close prices. We'll explore the data by asking and answering **three simple questions**:

1. **Distribution**: *What does the distribution of hourly close prices look like?*
   - We describe Q, test candidate models (Normal / Lognormal / Gamma), and judge fit quality visually and via AIC/BIC.

2. **Extremes**: *Which years are 'dry' vs 'wet' by average price level?*
   - We identify 2 low-mean years and 2 high-mean years, then compare their intra-annual signatures.

3. **Prediction**: *Can we predict tomorrow's price simply?*
   - We set up a naive baseline (persistence) and a linear regression as a starting point.

---

# Setup & Data Load

```{r setup}
suppressPackageStartupMessages({
  library(tidyverse)   # dplyr/ggplot2/readr/tidyr
  library(lubridate)   # parsing dates
  library(MASS)        # fitdistr for distribution fitting
})

# Find and load CSV
candidates <- c('data/btc_hourly_ohclv_ta.csv', 'btc_hourly_ohclv_ta.csv')
data_path <- candidates[file.exists(candidates)][1]
if (is.na(data_path)) stop('Could not find BTC CSV.')
message('Using: ', data_path)

df_raw <- readr::read_csv(data_path, show_col_types = FALSE)

# Parse datetime and define Q
df <- df_raw %>%
  mutate(
    DATETIME = ymd_hms(DATETIME, quiet = TRUE),
    Q = as.numeric(CLOSE)
  ) %>%
  filter(!is.na(DATETIME), !is.na(Q)) %>%
  arrange(DATETIME)

message('Rows: ', nrow(df), ' | Datetime range: ', min(df$DATETIME), ' → ', max(df$DATETIME))
```

---

# Helper Functions

```{r helpers_1}
# ECDF + AIC/BIC
ecdf_xy <- function(x) {
  x <- x[is.finite(x)]
  x <- sort(x)
  y <- seq_along(x) / length(x)
  list(x = x, y = y)
}

aic <- function(ll, k) 2 * k - 2 * ll
bic <- function(ll, k, n) k * log(n) - 2 * ll
```

```{r helpers_2}
# Moments (skewness / kurtosis) + descriptive stats
skewness_simple <- function(x) {
  x <- x[is.finite(x)]
  m <- mean(x)
  s <- sd(x)
  if (!is.finite(s) || s == 0) return(NA_real_)
  mean(((x - m) / s)^3)
}

excess_kurtosis_simple <- function(x) {
  x <- x[is.finite(x)]
  m <- mean(x)
  s <- sd(x)
  if (!is.finite(s) || s == 0) return(NA_real_)
  mean(((x - m) / s)^4) - 3
}

summarize_series <- function(x) {
  x <- x[is.finite(x)]
  p <- as.numeric(stats::quantile(x, probs = c(0.01, 0.05, 0.25, 0.75, 0.95, 0.99), names = FALSE))
  tibble(
    n = length(x), min = min(x), max = max(x),
    mean = mean(x), median = median(x), sd = sd(x),
    skew = skewness_simple(x), excess_kurtosis = excess_kurtosis_simple(x),
    p01 = p[1], p05 = p[2], p25 = p[3], p75 = p[4], p95 = p[5], p99 = p[6]
  )
}
```

```{r helpers_3}
# Distribution fitting functions
fit_norm <- function(x) {
  x <- x[is.finite(x)]
  mu <- mean(x); sigma <- sd(x)
  ll <- sum(dnorm(x, mean = mu, sd = sigma, log = TRUE))
  list(distribution = 'norm', params = list(mean = mu, sd = sigma), ll = ll, k = 2, n = length(x))
}

fit_lognorm <- function(x) {
  x <- x[is.finite(x) & x > 0]
  fit <- MASS::fitdistr(x, densfun = 'lognormal')
  ll <- as.numeric(logLik(fit))
  list(distribution = 'lognorm', params = as.list(fit$estimate), ll = ll, k = 2, n = length(x))
}

fit_gamma <- function(x) {
  x <- x[is.finite(x) & x > 0]
  out <- tryCatch({
    fit <- MASS::fitdistr(x, densfun = 'gamma')
    list(params = as.list(fit$estimate), ll = as.numeric(logLik(fit)))
  }, error = function(e) {
    # Fallback: method of moments
    m <- mean(x); v <- stats::var(x)
    if (!is.finite(v) || v <= 0) {
      return(list(params = list(shape = NA_real_, rate = NA_real_), ll = NA_real_))
    }
    shape <- m^2 / v; rate <- m / v
    ll <- sum(dgamma(x, shape = shape, rate = rate, log = TRUE))
    list(params = list(shape = shape, rate = rate), ll = ll)
  })
  list(distribution = 'gamma', params = out$params, ll = out$ll, k = 2, n = length(x))
}

ks_pvalue <- function(x, dist, params) {
  x <- x[is.finite(x)]
  out <- tryCatch({
    if (dist == 'norm') {
      stats::ks.test(x, 'pnorm', mean = params$mean, sd = params$sd)$p.value
    } else if (dist == 'lognorm') {
      stats::ks.test(x, 'plnorm', meanlog = params$meanlog, sdlog = params$sdlog)$p.value
    } else if (dist == 'gamma') {
      stats::ks.test(x, 'pgamma', shape = params$shape, rate = params$rate)$p.value
    } else NA_real_
  }, error = function(e) NA_real_)
  as.numeric(out)
}
```

---

# Question 1: Distribution of Close Price

## Prepare & Describe

```{r q1_stats}
Q <- df$Q[is.finite(df$Q)]
Q_pos <- Q[Q > 0]

stats_table <- summarize_series(Q)
knitr::kable(stats_table, digits = 3, caption = "Descriptive statistics of Q")
```

## Fit & Compare Models

```{r q1_fit}
fits <- list(
  fit_norm(Q),
  fit_lognorm(Q_pos),
  fit_gamma(Q_pos)
)

comparison <- purrr::map_dfr(fits, function(f) {
  x_for_ks <- if (f$distribution == 'norm') Q else Q_pos
  tibble(
    distribution = f$distribution,
    n_used = f$n,
    loglik = f$ll,
    AIC = aic(f$ll, f$k),
    BIC = bic(f$ll, f$k, f$n),
    KS_p = ks_pvalue(x_for_ks, f$distribution, f$params)
  )
}) %>% arrange(AIC)

knitr::kable(comparison, digits = 2, caption = "Model comparison (AIC/BIC)")
```

## Visualize Fit Quality

### Plot 1: Histogram + PDFs

```{r q1_plot_hist}
fits_named <- purrr::set_names(fits, purrr::map_chr(fits, 'distribution'))

ggplot(tibble(Q = Q_pos), aes(Q)) +
  geom_histogram(aes(y = after_stat(density)), bins = 120, fill = 'steelblue', alpha = 0.35) +
  stat_function(fun = dlnorm, args = fits_named$lognorm$params, linewidth = 1, colour = 'orange') +
  stat_function(fun = dgamma, args = fits_named$gamma$params, linewidth = 1, colour = 'green4') +
  stat_function(fun = dnorm, args = fits_named$norm$params, linewidth = 1, colour = 'red') +
  labs(title = 'Histogram + fitted PDFs', x = 'Q (CLOSE)', y = 'Density')
```

### Plot 2: ECDF + CDFs

```{r q1_plot_ecdf}
xgrid <- seq(min(Q_pos), max(Q_pos), length.out = 2000)
ec <- ecdf(Q_pos)

ggplot() +
  geom_step(aes(xgrid, ec(xgrid)), linewidth = 1, colour = 'black') +
  geom_line(aes(xgrid, plnorm(xgrid, !!!fits_named$lognorm$params)), linewidth = 1, colour = 'orange') +
  geom_line(aes(xgrid, pgamma(xgrid, !!!fits_named$gamma$params)), linewidth = 1, colour = 'green4') +
  geom_line(aes(xgrid, pnorm(xgrid, !!!fits_named$norm$params)), linewidth = 1, colour = 'red') +
  labs(title = 'ECDF + fitted CDFs', x = 'Q (CLOSE)', y = 'F(Q)')
```

### Plot 3: QQ Plot (log scale)

```{r q1_plot_qq}
logQ <- log(Q_pos)
qq <- qqnorm(logQ, plot.it = FALSE)
qq_df <- tibble(theoretical = qq$x, ordered = qq$y)

ggplot(qq_df, aes(theoretical, ordered)) +
  geom_point(size = 0.8, alpha = 0.7) +
  geom_abline(intercept = mean(logQ), slope = sd(logQ), colour = 'red') +
  labs(title = 'QQ plot: log(Q) vs Normal', x = 'Theoretical quantiles', y = 'Ordered values')
```

### Plot 4: Density (log10 x-scale)

```{r q1_plot_density_log}
ggplot(tibble(Q = Q_pos), aes(Q)) +
  geom_density(linewidth = 1, colour = 'steelblue') +
  scale_x_log10() +
  labs(title = 'Density with log10 x-scale', x = 'Q (log scale)', y = 'Density')
```

---

# Question 2: Dry & Wet Years

## Identify Extreme Years

```{r q2_select}
d <- df %>% mutate(YEAR = year(DATETIME), MONTH = month(DATETIME))

annual <- d %>%
  group_by(YEAR) %>%
  summarise(mean_Q = mean(Q), n = n(), .groups = 'drop') %>%
  arrange(mean_Q)

selected_dry <- annual %>% slice_head(n = 2) %>% mutate(label = 'dry')
selected_wet <- annual %>% slice_tail(n = 2) %>% mutate(label = 'wet')
selected <- bind_rows(selected_dry, selected_wet) %>% arrange(label, mean_Q)
selected_years <- selected$YEAR

knitr::kable(selected, caption = "Selected dry & wet years")
```

## Annual Summary

```{r q2_annual}
knitr::kable(annual %>% head(10), digits = 3, caption = "Annual mean Q (top/bottom)")
```

## Seasonal Signature

```{r q2_seasonal}
sel <- d %>% filter(YEAR %in% selected_years)

seasonal_signature <- sel %>%
  group_by(YEAR, MONTH) %>%
  summarise(
    mean_Q = mean(Q), median_Q = median(Q),
    q25 = quantile(Q, 0.25), q75 = quantile(Q, 0.75),
    n = n(), .groups = 'drop'
  )

knitr::kable(seasonal_signature %>% head(12), digits = 3, caption = "Seasonal stats (first 12 rows)")
```

## Visualize Dry/Wet Comparison

### Plot 1: Time Series (faceted)

```{r q2_plot_ts}
ggplot(sel, aes(DATETIME, Q)) +
  geom_line(linewidth = 0.3) +
  facet_wrap(~ YEAR, scales = 'free_x', ncol = 2) +
  labs(title = 'Time series of Q (selected years)', x = 'Date', y = 'Q')
```

### Plot 2: Cumulative Sum

```{r q2_plot_cumsum}
cum_df <- sel %>%
  arrange(YEAR, DATETIME) %>%
  group_by(YEAR) %>%
  mutate(cum_Q = cumsum(Q)) %>%
  ungroup()

ggplot(cum_df, aes(DATETIME, cum_Q, colour = factor(YEAR))) +
  geom_line(linewidth = 0.6) +
  labs(title = 'Annual cumulative sum of Q', x = 'Date', y = 'Cumulative Q', colour = 'Year')
```

### Plot 3: Monthly Boxplots

```{r q2_plot_boxplots}
ggplot(sel, aes(factor(MONTH), Q, fill = factor(YEAR))) +
  geom_boxplot(outlier.shape = NA) +
  labs(title = 'Monthly distribution of Q (selected years)', x = 'Month', y = 'Q', fill = 'Year')
```

### Plot 4: Monthly Means

```{r q2_plot_monthly_means}
monthly_means <- sel %>%
  group_by(YEAR, MONTH) %>%
  summarise(mean_Q = mean(Q), .groups = 'drop')

ggplot(monthly_means, aes(MONTH, mean_Q, colour = factor(YEAR))) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = 1:12) +
  labs(title = 'Monthly mean of Q (selected years)', x = 'Month', y = 'Mean Q', colour = 'Year')
```

---

# Question 3: Simple Price Prediction

## Build & Split Dataset

```{r q3_data}
model_df <- df %>%
  arrange(DATETIME) %>%
  mutate(
    y = dplyr::lead(Q, 1),
    lag1 = dplyr::lag(Q, 1),
    lag24 = dplyr::lag(Q, 24),
    ret1 = Q / dplyr::lag(Q, 1) - 1
  ) %>%
  dplyr::select(
    DATETIME, Q, y,
    lag1, lag24, ret1,
    SMA_20, EMA_12, EMA_26,
    MACD, MACD_SIGNAL, MACD_DIFF,
    RSI, BB_WIDTH,
    STOCH_K, STOCH_D,
    MFI, ATR,
    VOLATILITY_30D, PRICE_VOLATILITY_30D, HL_VOLATILITY_30D
  ) %>%
  tidyr::drop_na()

n_total <- nrow(model_df)
train_n <- floor(0.80 * n_total)
train <- model_df[1:train_n, ]
test <- model_df[(train_n + 1):n_total, ]

message('Total: ', n_total, ' | Train: ', nrow(train), ' | Test: ', nrow(test))
```

## Define Metrics & Fit Models

```{r q3_metrics}
rmse <- function(y, yhat) sqrt(mean((yhat - y)^2))
mae <- function(y, yhat) mean(abs(yhat - y))
mape <- function(y, yhat) mean(abs((yhat - y) / y)) * 100
```

```{r q3_fit}
# Naive persistence baseline
test$pred_naive <- test$Q

# Linear regression
fit_lm <- lm(
  y ~ lag1 + lag24 + ret1 + SMA_20 + RSI + MACD + BB_WIDTH + ATR + VOLATILITY_30D,
  data = train
)
test$pred_lm <- predict(fit_lm, newdata = test)

# Metrics comparison
metrics <- tibble(
  model = c('naive_persistence', 'linear_regression'),
  RMSE = c(rmse(test$y, test$pred_naive), rmse(test$y, test$pred_lm)),
  MAE  = c(mae(test$y, test$pred_naive),  mae(test$y, test$pred_lm)),
  MAPE = c(mape(test$y, test$pred_naive), mape(test$y, test$pred_lm))
)

knitr::kable(metrics, digits = 2, caption = "Model performance on test set")
```

## Visualize Predictions

### Plot 1: Last 500 Test Points

```{r q3_plot_last500}
N <- min(500, nrow(test))
plot_df <- test %>%
  tail(N) %>%
  dplyr::select(DATETIME, actual = y, pred_naive, pred_lm) %>%
  tidyr::pivot_longer(cols = c(actual, pred_naive, pred_lm), names_to = 'series', values_to = 'value')

ggplot(plot_df, aes(DATETIME, value, colour = series)) +
  geom_line(linewidth = 0.6) +
  labs(title = 'Next-hour prediction (last 500 test points)', x = 'Date', y = 'Price')
```

### Plot 2: Predicted vs Actual

```{r q3_plot_scatter}
ggplot(test, aes(y, pred_lm)) +
  geom_point(alpha = 0.25, size = 0.8) +
  geom_abline(intercept = 0, slope = 1, colour = 'red') +
  labs(title = 'Linear model: Predicted vs Actual (test)', x = 'Actual y', y = 'Predicted y')
```

---

# Takeaways

## Key Findings

- **Distribution**: The close price follows a right-skewed distribution; the Lognormal and Gamma models fit better than Normal. Log-transformation stabilizes the shape.
  
- **Seasonality**: Dry vs wet years differ not just in annual mean but also in monthly patterns. Low-price years tend to be flatter; high-price years show more seasonal variation.
  
- **Prediction**: The naive persistence baseline is hard to beat for very short horizons (1-hour ahead). Linear regression with technical indicators offers modest improvement but may need richer features/models.

## Next Steps

1. **Richer target**: Try log-returns instead of raw price; they may be more predictable.
2. **Temporal validation**: Use walk-forward or time-series cross-validation instead of a single train/test split.
3. **More models**: Add ridge/lasso, random forest, XGBoost, and compare.
4. **Deeper seasonality**: Decompose into trend + seasonal + residual using STL or similar.

---

## References

- Nakamoto, S. (2008). *Bitcoin: A Peer-to-Peer Electronic Cash System*.
- Bollinger, J. (2002). *Bollinger on Bollinger Bands*. McGraw-Hill.
- Wilder, J. W. (1978). *New Concepts in Technical Trading Systems*. Trend Research.
